{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bd9100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-19 14:51:55.159990: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./twitter_training.csv')\n",
    "\n",
    "df.info()\n",
    "\n",
    "# Load the Spacy NLP model for English\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import re\n",
    "\n",
    "remove_punct_num = lambda x: re.sub(r'[^\\w\\s]|[\\d]+', '', x)\n",
    "\n",
    "corpus=df['im getting on borderlands and i will murder you all ,'].astype(str)\n",
    "\n",
    "corpus_cleaned = corpus.apply(remove_punct_num)\n",
    "\n",
    "type(corpus_cleaned)\n",
    "\n",
    "sentiment=df['Positive']\n",
    "\n",
    "sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus_cleaned, sentiment, test_size=0.1, random_state=42)\n",
    "\n",
    "len(X_train)==len(y_train)\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize the text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "X_train = [preprocess(text) for text in X_train]\n",
    "X_test = [preprocess(text) for text in X_test]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925df3ac",
   "metadata": {},
   "source": [
    "# With TF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "147232a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv('./twitter_training.csv')\n",
    "\n",
    "\n",
    "remove_punct_num = lambda x: re.sub(r'[^\\w\\s]|[\\d]+', '', x)\n",
    "corpus = df['im getting on borderlands and i will murder you all ,'].astype(str)\n",
    "corpus_cleaned = corpus.apply(remove_punct_num)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize the text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "corpus_cleaned = [preprocess(text) for text in corpus_cleaned]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(corpus_cleaned)\n",
    "X = tokenizer.texts_to_sequences(corpus_cleaned)\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91a05514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Positive'] = le.fit_transform(df['Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b99f1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e2c4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d98ec2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 3] = 2\n",
    "y_test[y_test == 3] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58230912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(5000, 64, input_length=100),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b7fd56ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9231c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2101/2101 [==============================] - 27s 12ms/step - loss: 0.6766 - accuracy: 0.7149\n",
      "Epoch 2/10\n",
      "2101/2101 [==============================] - 25s 12ms/step - loss: 0.3920 - accuracy: 0.8470\n",
      "Epoch 3/10\n",
      "2101/2101 [==============================] - 24s 12ms/step - loss: 0.2461 - accuracy: 0.9050\n",
      "Epoch 4/10\n",
      "2101/2101 [==============================] - 24s 12ms/step - loss: 0.1778 - accuracy: 0.9310\n",
      "Epoch 5/10\n",
      "2101/2101 [==============================] - 25s 12ms/step - loss: 0.1462 - accuracy: 0.9432\n",
      "Epoch 6/10\n",
      "2101/2101 [==============================] - 25s 12ms/step - loss: 0.1292 - accuracy: 0.9493\n",
      "Epoch 7/10\n",
      "2101/2101 [==============================] - 24s 12ms/step - loss: 0.1160 - accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "2101/2101 [==============================] - 25s 12ms/step - loss: 0.1101 - accuracy: 0.9560\n",
      "Epoch 9/10\n",
      "2101/2101 [==============================] - 25s 12ms/step - loss: 0.1022 - accuracy: 0.9594\n",
      "Epoch 10/10\n",
      "2101/2101 [==============================] - 24s 12ms/step - loss: 0.0996 - accuracy: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9f03e0df0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e0271f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7a44b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_predictions = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6dfc43a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, ..., 1, 2, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c4060c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8570089704110323\n",
      "Precision: 0.8571459325082399\n",
      "Recall: 0.8570089704110323\n",
      "F1 Score: 0.8561287280150716\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, category_predictions))\n",
    "print(\"Precision:\", precision_score(y_test, category_predictions, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, category_predictions, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, category_predictions, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c48509",
   "metadata": {},
   "source": [
    "# This is how a untuned model significantly increases our accuracy on unseen data! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
